{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_func(x, t):\n",
    "    return x**3*t + 2*x**2*torch.sqrt(t) + torch.sin(x) + 3*torch.cos(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 output_dim: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(1, 64)\n",
    "        \n",
    "        self.fc3 = nn.Linear(128, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, output_dim)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.act(self.fc1(x))\n",
    "        t = self.act(self.fc2(t))\n",
    "        xt = torch.cat((x, t), dim=1)\n",
    "        xt = self.act(self.fc3(xt))\n",
    "        xt = self.act(self.fc4(xt))\n",
    "        return self.fc5(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIterableDataset(IterableDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x_dim = 64\n",
    "        self.t_dim = 1\n",
    "    \n",
    "    def generator(self):\n",
    "        while True:\n",
    "            x = torch.rand((self.x_dim))\n",
    "            t = torch.rand((self.t_dim))\n",
    "            y = complex_func(x, t)\n",
    "            yield x, t, y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.8135509490966797\n",
      "Epoch: 1, Loss: 0.5046282410621643\n",
      "Epoch: 2, Loss: 0.6681536436080933\n",
      "Epoch: 3, Loss: 0.6689860224723816\n",
      "Epoch: 4, Loss: 0.40377163887023926\n",
      "Epoch: 5, Loss: 0.5392351746559143\n",
      "Epoch: 6, Loss: 0.6561574935913086\n",
      "Epoch: 7, Loss: 0.497970312833786\n",
      "Epoch: 8, Loss: 0.4703254997730255\n",
      "Epoch: 9, Loss: 0.4264187216758728\n",
      "Epoch: 10, Loss: 0.33536186814308167\n",
      "Epoch: 11, Loss: 0.4799478352069855\n",
      "Epoch: 12, Loss: 0.2943488359451294\n",
      "Epoch: 13, Loss: 0.23191973567008972\n",
      "Epoch: 14, Loss: 0.6100165843963623\n",
      "Epoch: 15, Loss: 0.4604904353618622\n",
      "Epoch: 16, Loss: 0.2953226566314697\n",
      "Epoch: 17, Loss: 0.36538827419281006\n",
      "Epoch: 18, Loss: 0.4199337065219879\n",
      "Epoch: 19, Loss: 0.41898396611213684\n",
      "Epoch: 20, Loss: 0.4573240876197815\n",
      "Epoch: 21, Loss: 0.5226966142654419\n",
      "Epoch: 22, Loss: 0.30232709646224976\n",
      "Epoch: 23, Loss: 0.5510480403900146\n",
      "Epoch: 24, Loss: 0.48824018239974976\n",
      "Epoch: 25, Loss: 0.36434581875801086\n",
      "Epoch: 26, Loss: 0.31575390696525574\n",
      "Epoch: 27, Loss: 0.2942257225513458\n",
      "Epoch: 28, Loss: 0.30381664633750916\n",
      "Epoch: 29, Loss: 0.3117000162601471\n",
      "Epoch: 30, Loss: 0.43662959337234497\n",
      "Epoch: 31, Loss: 0.21137283742427826\n",
      "Epoch: 32, Loss: 0.23655828833580017\n",
      "Epoch: 33, Loss: 0.3139936327934265\n",
      "Epoch: 34, Loss: 0.2840888202190399\n",
      "Epoch: 35, Loss: 0.5137372016906738\n",
      "Epoch: 36, Loss: 0.310485303401947\n",
      "Epoch: 37, Loss: 0.26904231309890747\n",
      "Epoch: 38, Loss: 0.4848974943161011\n",
      "Epoch: 39, Loss: 0.3491659462451935\n",
      "Epoch: 40, Loss: 0.2580943703651428\n",
      "Epoch: 41, Loss: 0.3961948752403259\n",
      "Epoch: 42, Loss: 0.4518783390522003\n",
      "Epoch: 43, Loss: 0.46290627121925354\n",
      "Epoch: 44, Loss: 0.3634469211101532\n",
      "Epoch: 45, Loss: 0.34035661816596985\n",
      "Epoch: 46, Loss: 0.18059222400188446\n",
      "Epoch: 47, Loss: 0.4146552085876465\n",
      "Epoch: 48, Loss: 0.4743002653121948\n",
      "Epoch: 49, Loss: 0.46063387393951416\n",
      "Epoch: 50, Loss: 0.2348800003528595\n",
      "Epoch: 51, Loss: 0.32998326420783997\n",
      "Epoch: 52, Loss: 0.29948750138282776\n",
      "Epoch: 53, Loss: 0.2906051278114319\n",
      "Epoch: 54, Loss: 0.2870328426361084\n",
      "Epoch: 55, Loss: 0.37218427658081055\n",
      "Epoch: 56, Loss: 0.195717453956604\n",
      "Epoch: 57, Loss: 0.4019010365009308\n",
      "Epoch: 58, Loss: 0.38514745235443115\n",
      "Epoch: 59, Loss: 0.31262677907943726\n",
      "Epoch: 60, Loss: 0.4212363064289093\n",
      "Epoch: 61, Loss: 0.3912489116191864\n",
      "Epoch: 62, Loss: 0.3674478530883789\n",
      "Epoch: 63, Loss: 0.33156952261924744\n",
      "Epoch: 64, Loss: 0.32296663522720337\n",
      "Epoch: 65, Loss: 0.5233185291290283\n",
      "Epoch: 66, Loss: 0.3626052439212799\n",
      "Epoch: 67, Loss: 0.38946977257728577\n",
      "Epoch: 68, Loss: 0.35314419865608215\n",
      "Epoch: 69, Loss: 0.3987874686717987\n",
      "Epoch: 70, Loss: 0.17656005918979645\n",
      "Epoch: 71, Loss: 0.2823066711425781\n",
      "Epoch: 72, Loss: 0.3452030420303345\n",
      "Epoch: 73, Loss: 0.2292965054512024\n",
      "Epoch: 74, Loss: 0.39241427183151245\n",
      "Epoch: 75, Loss: 0.4447811543941498\n",
      "Epoch: 76, Loss: 0.31079554557800293\n",
      "Epoch: 77, Loss: 0.3492295742034912\n",
      "Epoch: 78, Loss: 0.31978243589401245\n",
      "Epoch: 79, Loss: 0.3513670265674591\n",
      "Epoch: 80, Loss: 0.31922829151153564\n",
      "Epoch: 81, Loss: 0.3773740530014038\n",
      "Epoch: 82, Loss: 0.3867761790752411\n",
      "Epoch: 83, Loss: 0.4640611708164215\n",
      "Epoch: 84, Loss: 0.3506125807762146\n",
      "Epoch: 85, Loss: 0.5272294878959656\n",
      "Epoch: 86, Loss: 0.3102377653121948\n",
      "Epoch: 87, Loss: 0.37226784229278564\n",
      "Epoch: 88, Loss: 0.3638664484024048\n",
      "Epoch: 89, Loss: 0.5423575639724731\n",
      "Epoch: 90, Loss: 0.195497065782547\n",
      "Epoch: 91, Loss: 0.24342459440231323\n",
      "Epoch: 92, Loss: 0.3395802676677704\n",
      "Epoch: 93, Loss: 0.2797956168651581\n",
      "Epoch: 94, Loss: 0.41062402725219727\n",
      "Epoch: 95, Loss: 0.4024512469768524\n",
      "Epoch: 96, Loss: 0.35357925295829773\n",
      "Epoch: 97, Loss: 0.40138623118400574\n",
      "Epoch: 98, Loss: 0.5021430850028992\n",
      "Epoch: 99, Loss: 0.2526514530181885\n"
     ]
    }
   ],
   "source": [
    "dataset = MyIterableDataset()\n",
    "ds_loader = DataLoader(dataset, batch_size=4)\n",
    "\n",
    "mlp = MLP(input_dim=64, output_dim=64)\n",
    "mlp.train()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "for epoch in range(100):\n",
    "    for i, data in enumerate(ds_loader):\n",
    "        x, t, y = data\n",
    "        optimizer.zero_grad()\n",
    "        pred = mlp(x, t)\n",
    "        loss = loss_func(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i > 1000:\n",
    "            break\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([3.1364, 3.1241, 3.1781, 4.0548, 4.1723, 4.1959, 4.2630, 3.1958, 3.4458,\n",
      "        4.1777, 4.3326, 3.2465, 4.4264, 3.0197, 3.3294, 3.6239, 3.0075, 3.2230,\n",
      "        4.2677, 4.0143, 4.3521, 3.1582, 3.2274, 3.4675, 3.8911, 4.1819, 3.5897,\n",
      "        3.2023, 4.1943, 3.6479, 3.6529, 3.2884, 3.6018, 4.3290, 3.8149, 4.2488,\n",
      "        3.0523, 3.1200, 3.1330, 4.2276, 3.2416, 3.8995, 3.4058, 4.1589, 3.6061,\n",
      "        3.3893, 3.4294, 3.5833, 3.3441, 3.4656, 3.3275, 3.2203, 3.1620, 3.5418,\n",
      "        3.8082, 4.4065, 4.0568, 3.2071, 3.2362, 3.2202, 3.0992, 4.3898, 3.0008,\n",
      "        4.1357]), pred: tensor([[3.6153, 3.1494, 3.4698, 3.9832, 3.6665, 4.1834, 4.1734, 3.7083, 3.3788,\n",
      "         4.7665, 3.8076, 3.1714, 3.9558, 3.3482, 3.6533, 3.4255, 2.8138, 3.2836,\n",
      "         4.0509, 3.6887, 3.5982, 3.8802, 2.9503, 3.3829, 3.9513, 3.8507, 3.9052,\n",
      "         3.0377, 4.2483, 3.6220, 3.7094, 3.5375, 3.7382, 3.6356, 3.9911, 3.8013,\n",
      "         3.4487, 3.1081, 3.2295, 4.1512, 3.5629, 4.0895, 3.6865, 3.7793, 3.6243,\n",
      "         3.2905, 3.3225, 3.7306, 2.9068, 3.4788, 3.1665, 3.4500, 3.6206, 3.8448,\n",
      "         3.8459, 4.3635, 4.1681, 3.6967, 2.9917, 3.1703, 2.8771, 3.6749, 3.1769,\n",
      "         3.8595]])\n",
      "y-pred: tensor([[-0.4790, -0.0253, -0.2918,  0.0716,  0.5058,  0.0126,  0.0896, -0.5124,\n",
      "          0.0669, -0.5888,  0.5251,  0.0751,  0.4707, -0.3285, -0.3239,  0.1984,\n",
      "          0.1937, -0.0605,  0.2168,  0.3256,  0.7539, -0.7220,  0.2771,  0.0846,\n",
      "         -0.0602,  0.3312, -0.3155,  0.1646, -0.0540,  0.0259, -0.0565, -0.2492,\n",
      "         -0.1364,  0.6933, -0.1762,  0.4475, -0.3963,  0.0119, -0.0966,  0.0764,\n",
      "         -0.3212, -0.1900, -0.2807,  0.3796, -0.0182,  0.0988,  0.1069, -0.1473,\n",
      "          0.4373, -0.0132,  0.1610, -0.2296, -0.4586, -0.3030, -0.0378,  0.0430,\n",
      "         -0.1113, -0.4897,  0.2445,  0.0499,  0.2222,  0.7148, -0.1761,  0.2763]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1, 64))\n",
    "t = torch.rand((1, 1))\n",
    "y = complex_func(x.squeeze(), t.squeeze())\n",
    "with torch.no_grad():\n",
    "    pred = mlp(x, t)\n",
    "    print(f\"y: {y}, pred: {pred}\")\n",
    "    print(f\"y-pred: {y-pred}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
